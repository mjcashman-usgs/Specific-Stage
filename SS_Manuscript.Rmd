---
title: "Patapsco Gage/Sediment analysis"
author: "Matthew J Cashman"
date: "September 30, 2018"
output:
  html_notebook: 
    toc: yes
  html_document:
    df_print: paged
---

This code is the draft notebook, and framework for the manuscript for the Patapsco River dam removal projects. 


# Project Prep

## Load packages
```{r Load Required Packages, echo=TRUE, message=TRUE, warning=TRUE, paged.print=TRUE}
if (!require("pacman")) install.packages("pacman"); library(pacman)
p_load(tidyverse, dataRetrieval, data.table, microbenchmark,fasttime, leaflet, sp, fs, gridExtra, rjson)
```

## Define Sites
Multiple sites can be defined under Sites. Project will be the grouping of sites and name of the export folder. read_NWIS if set to TRUE will pull from NWIS web (this can take 10-15 minutes to important instantaneous data), or if set to FALSE will read in local data that is already retrieved and saved from NWIS. After the first NWIS import, data will be saved locally automatically. 

```{r Retrieve gage site information from NWIS}
Sites <- c("01589000","01589025","01589035")
Project <- "Patapsco"
read_NWIS <- FALSE
SiteInfo<-readNWISsite(Sites)
SiteInfo
```

## Plot locations in leaflet
```{r}
leaflet(data = SiteInfo) %>% addTiles() %>%
  addCircleMarkers(~dec_long_va, ~dec_lat_va, color="black", radius=8, popup = ~as.character(paste0(site_no, ": ", station_nm)), label = ~as.character(paste0(site_no, ": ", station_nm)))
```

#Import Gage Data
Let's figure out what data is available at these 3 gage locations
```{r WhatData}
whatNWISdata(siteNumber=Sites, service=c("uv","dv"),statCd = "00003") %>%
  select(agency_cd,site_no,station_nm,parm_cd,stat_cd,begin_date,end_date,count_nu) %>%
  arrange(parm_cd, stat_cd) 
```

USGS parameter codes used by NWIS:
* 00060 - Discharge
* 00065 - Gage height
* 63680 - Turbidity
* 80154 - SSC
* 80155 - SSQ

We will pull in all data for these parameters for the entire period of record.
```{r dataRetrieval Settings}
startDate <- "2010-10-01"
endDate <- "2018-10-01"
par <- c("00060","00065", "63680", "80154", "80155")
```

If read_NWIS has been previously set to TRUE, this chunk will pull from NWIS web (this can take 10-15 minutes to important instantaneous data) and save a copy locally for later analysis. If read_NWIS has been set to FALSE, this chunk will read in local data that was already retrieved and saved from NWIS. 
```{r Load in data from NWIS or locally based on read_NWIS}
writeDir <<- paste0("./NWIS_pulls/",Project)
if (read_NWIS == TRUE){
  message("Reading uv data")
  uv_data <<- readNWISuv(siteNumbers = Sites,
            parameterCd = par,
            startDate = "",
            endDate = "",
            tz = "America/New_York") %>% renameNWISColumns() %>% 
            filter(Flow_Inst!=-999999) %>%
            filter(GH_Inst!=-999999)
  
  message("Reading dv data")
  dv_data <<- readNWISdv(siteNumbers = Sites,
            parameterCd = par,
            startDate = "",
            endDate = "") %>% renameNWISColumns()%>% 
            filter(Turb!=-999999) %>%
            filter(Flow!=-999999)
  message("Wring NWIS data locally for later loads")
  dir_create(writeDir) #Create Export directory
  fwrite(dv_data,paste0(writeDir,"/dv_data.csv"))
  fwrite(uv_data,paste0(writeDir,"/uv_data.csv"))
  } else if(read_NWIS == FALSE)  {
  message("read_NWIS is defined to FALSE. Will read local files")
  message("Reading local Daily Data ")
    dv_data <- fread(paste0(writeDir,"/dv_data.csv"), colClasses=c(site_no="character"))
    dv_data$Date <- as.Date(dv_data$Date)
  message("Reading local Continuous Data")
    uv_data <- fread(paste0(writeDir,"/uv_data.csv"), colClasses=c(site_no="character"))
    uv_data$dateTime <- fastPOSIXct(uv_data$dateTime)
  } else{
    message("read_NWIS not defined. Data not loaded")
  }
```

#Analysis of time-series records
Now that we have time-series data loaded into our environment, let's explore what we can see from these datasets.
```{r Generate DV Cumulative Plots}
data<-dv_data %>%
  select(Date, site_no,Flow,Turb) %>%
    na.omit() %>% group_by(site_no) %>% mutate(cumQ=cumsum(Flow),cumT=cumsum(Turb))
  
ggplot(data, aes(x=cumQ, y=cumT, group=site_no, color=site_no))+
  geom_path(size=2)+
  scale_color_viridis_d()
```

```{r Generate time-explicit DV cumulative plots}
data %>%
  gather(variable, value, c(cumQ,cumT)) %>%
ggplot(aes(x=Date, y=value, group=site_no, color=site_no))+
  geom_path(size=2) +
  facet_wrap(~variable, scales = "free_y") +
  scale_color_viridis_d()
```

```{r Generate DV transport plots}
data<-dv_data %>%
  select(Date, site_no,Flow,Turb) %>%
    na.omit() %>% group_by(site_no) %>% mutate(cumQ=cumsum(Flow),cumT=cumsum(Turb)) %>%
  filter(Date < "2014-1-1") %>%
  separate(Date, by="-", into = c("Year","Month","Day")) %>%
  unite(MonthYear,Year,Month,sep=".") 

  ggplot(data, aes(x=log(Flow), y=log(Turb), group=site_no, color=site_no))+
  geom_point(size=1.5, alpha=0.5)+
  facet_wrap(~MonthYear)+
  scale_color_viridis_d()+
  geom_smooth(method="lm", se=TRUE)

```

## Storm-by-storm analysis
```{r Identify when storms occurred}
dv_data %>%
  select(Date, site_no,Flow,Turb) %>%
    na.omit() %>% group_by(site_no) %>% mutate(cumQ=cumsum(Flow),cumT=cumsum(Turb)) %>%
  filter(Date < "2013-1-1") %>%
 # separate(Date, by="-", into = c("Year","Month","Day")) %>%
  #unite(MonthYear,Year,Month,sep=".") %>%
  ggplot(aes(x=Date, y=Flow, group=site_no, color=site_no))+
  geom_line(size=1.5, alpha=0.5)+
  scale_color_viridis_d()+
  geom_smooth(span=0.03, SE=FALSE)
```

```{r Storm picker smoothing algorithm}
argmax <- function(x, y, w=1, ...) {
  require(zoo)
  n <- length(y)
  y.smooth <- loess(y ~ x, ...)$fitted
  y.max <- rollapply(zoo(y.smooth), 2*w+1, max, align="center")
  delta <- y.max - y.smooth[-c(1:w, n+1-1:w)]
  i.max <- which(delta <= 0) + w
  list(x=x[i.max], i=i.max, y.hat=y.smooth)
}
test <- function(w, span) {
  peaks <- argmax(x, y, w=w, span=span)

  plot(x, y, cex=0.75, col="Gray", main=paste("w = ", w, ", span = ", span, sep=""))
  lines(x, peaks$y.hat,  lwd=2) #$
  y.min <- min(y)
  points(x[peaks$i], peaks$y.hat[peaks$i], col="Red", pch=19, cex=1.25)
}
library(tidyverse)
data <- dv_data %>%
  select(Date, site_no,Flow,Turb) %>%
    na.omit() %>% group_by(site_no) %>% mutate(cumQ=cumsum(Flow),cumT=cumsum(Turb)) %>%
  filter(Date < "2017-1-1") %>% filter(site_no=="01589035")
x <- as.numeric(data$Date)
y <- log(data$Flow)
par(mfrow=c(4,1))
plot(x,y)
lines(x,y)
test(1, 0.002)
test(1, 0.005)
test(2, 0.02)
length(x)
peaks <- argmax(x, y, w=1, span=0.005)
message(length(peaks$x), "storms identified at Site 01589035")
```

```{r Plotting hysteresis of storm, fig.height=4, fig.width=8}
peak.no <- 2
peak_date <- data %>%
  filter(Date %in% as.Date(peaks$x))
target_peak_long<-format(peak_date[[1]][[peak.no]], format="%B %d, %Y")
target_peak<-peak_date[[1]][[peak.no]]
target_peak

storm_uv<-uv_data %>%
  #filter(site_no==site) %>%
  filter(dateTime > target_peak-2 & dateTime < target_peak+2)

temp <- storm_uv %>%
  filter(site_no=="01589035") 
min <- min(temp$dateTime)
mean <- mean(temp$dateTime)
max <- max(temp$dateTime)
storm_uv$dateTime
storm_uv %>%
  gather(variable, value, c(Flow_Inst,Turb_Inst)) %>%
  #filter(site_no==site) %>%
  ggplot(aes(x=dateTime, y= value, color=as.numeric(dateTime)))+
  geom_path(size=1)+
  facet_grid(variable~site_no, scales = "free_y")+
  scale_color_viridis_c(name="Date and Time",breaks=as.numeric(c(min,mean,max)),labels=c(min, mean, max))+
  ggtitle(paste0("Hydrograph for storm #:",peak.no,"   ", target_peak_long))

```

```{r Storm specific Hysterists loop, fig.height=4, fig.width=12}
storm_uv %>%
  ggplot(aes(x=Flow_Inst, y=Turb_Inst,color=as.numeric(dateTime)))+
  geom_path(size=2)+
  facet_wrap(~site_no)+
  scale_color_viridis_c(name="Date and Time", breaks=as.numeric(c(min,mean,max)),labels=c(min, mean, max))+
  ggtitle(paste0("Hysteresis loops for storm #:",peak.no,"   ", target_peak))
```

```{r Loop plot to save all hysteresis results}
for (i in seq(peaks$x)){
tryCatch({
 peak.no <- i
peak_date <- data %>%
  filter(Date %in% as.Date(peaks$x))
target_peak_long<-format(peak_date[[1]][[peak.no]], format="%B %d, %Y")
target_peak<-peak_date[[1]][[peak.no]]
target_peak
 <- paste0("./Patapsco_Hysteresis/")
dir_create() #Create Export directory

storm_uv<-uv_data %>%
  #filter(site_no==site) %>%
  filter(dateTime > target_peak-2 & dateTime < target_peak+2)

temp <- storm_uv %>%
  filter(site_no=="01589035") 
min <- min(temp$dateTime)
mean <- mean(temp$dateTime)
max <- max(temp$dateTime)
storm_uv$dateTime

storm_uv %>%
  gather(variable, value, c(Flow_Inst,Turb_Inst)) %>%
  #filter(site_no==site) %>%
  ggplot(aes(x=dateTime, y= value, color=as.numeric(dateTime)))+
  geom_path(size=1)+
  facet_grid(variable~site_no, scales = "free_y")+
  theme_bw()+
  scale_color_viridis_c(name="Date and Time",breaks=as.numeric(c(min,mean,max)),labels=c(min, mean, max))+
  ggtitle(paste0("Hydrograph for storm #:",peak.no,"   ", target_peak_long))
ggsave(paste0(,"Storm-",i," Hydrograph.png"),width=9,height=6)

storm_uv %>%
  ggplot(aes(x=Flow_Inst, y=Turb_Inst,color=as.numeric(dateTime)))+
  geom_path(size=2)+
  theme_bw()+
  facet_wrap(~site_no)+
  scale_color_viridis_c(name="Date and Time", breaks=as.numeric(c(min,mean,max)),labels=c(min, mean, max))+
  ggtitle(paste0("Hysteresis loops for storm #:",peak.no,"   ", target_peak))
#ggsave(paste0(,"Storm-",i," Hysteresis.png"),width=12)
})
}

```

```{r Loop plot for all hysteresis results for 1 site, message=FALSE, warning=FALSE}
site <- "01589025"

seq <- 173:185
groblength<-1
plot_list = list()
for (i in seq){
peak.no <- i

peak_date <- data %>%
  filter(Date %in% as.Date(peaks$x))

target_peak<-peak_date[[1]][[peak.no]]
  
storm_uv<-uv_data %>%
  filter(site_no==site) %>%
  filter(dateTime > target_peak-2 & dateTime < target_peak+2)

temp <- storm_uv %>%
  filter(site_no=="01589035") 
min <- min(temp$dateTime)
mean <- mean(temp$dateTime)
max <- max(temp$dateTime)


name <-paste0("plot",i) 
plot_list[[groblength]] <- ggplot(storm_uv,aes(x=Flow_Inst, y=Turb_Inst,color=as.numeric(dateTime)))+
                      geom_path(size=2)+
                      theme_bw(base_size = 8)+
                      scale_color_viridis_c(name="Date and Time", breaks=as.numeric(c(min,mean,max)),labels=c(min, mean, max))+
                      ggtitle(paste0("#",peak.no," - ", target_peak))+ guides(color=FALSE)
groblength <- groblength+1
}

g<-do.call(arrangeGrob,plot_list)

#ggsave(file=paste0(,"Hysteresis",site,"-", min(seq),"-", max(seq),".png"), g, height=7, width=7) #saves g

```
```{r tidy attempted remake of above}
site <- "01589035"

list_data = list()

for (i in seq(peaks$x)){
peak.no <- i
peak_date <- data %>%
  filter(Date %in% as.Date(peaks$x))

target_peak<-peak_date[[1]][[peak.no]]
  
storm_uv<-uv_data %>%
  filter(dateTime > target_peak-2 & dateTime < target_peak+2)
start<-storm_uv$dateTime[[1]]
storm_uv<-storm_uv %>% 
  mutate(timefrom = (dateTime-start))
storm_uv$i <- i
storm_uv$storm_id <- paste0("Storm #",peak.no," - ", target_peak)
list_data[[i]] <- storm_uv
}

storm_data<-rbindlist(list_data)

storm_data %>%
  #filter(site_no==site) %>%
  filter(i>=170 & i <= 186) %>%
  ggplot(aes(x=Flow_Inst, y=Turb_Inst))+
    geom_path(size=2, alpha=0.8, aes(color=factor(site_no)))+
    scale_x_log10()+
  scale_y_log10()+
              theme_bw(base_size = 8)+
                #      scale_color_viridis_d(name="Date and Time", breaks=as.numeric(c(min,mean,max)),labels=c(min, mean, max))+
                      ggtitle(paste0("Hysteresis Grid for USGS Site  ",site))+
  #guides(color=FALSE)+
  facet_wrap(~storm_id)
  
```

