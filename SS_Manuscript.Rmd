---
title: "Patapsco Gage/Sediment analysis"
author: "Matthew J Cashman"
date: "September 30, 2018"
output:
  html_document:
    df_print: paged
  html_notebook: 
    toc: yes
---

This code is the draft notebook and framework for the manuscript for the Patapsco River dam removal project 


# Project Prep

## Load packages
```{r Load Required Packages, echo=TRUE, message=TRUE, warning=TRUE, paged.print=TRUE}
if (!require("pacman")) install.packages("pacman"); library(pacman)
p_load(tidyverse, dataRetrieval, data.table, leaflet, sp, fs, gridExtra, plotly)
```
```{r theme creation, include=FALSE}
theme_ss <- function(base_size, base_family) {
  library(grid)
  library(ggthemes)
  (theme_foundation(base_size=base_size, base_family=base_family)
    + theme(plot.title = element_text(size = rel(1), hjust = 0.5),
            plot.subtitle = element_text(size = rel(01), hjust = 0.5),
            text = element_text(),
            panel.background = element_rect(colour = NA),
            plot.background = element_rect(colour = NA),
            panel.border = element_rect(colour = NA),
            axis.title = element_text(size = rel(1)),
            axis.title.y = element_text(angle=90,vjust =2, size = rel(0.9)),
            axis.title.x = element_text(size = rel(0.9)),
            axis.text.y = element_text(size=rel(0.8)), 
            axis.text.x = element_text(size=rel(0.8)), 
            axis.line = element_line(colour="black"),
            axis.ticks = element_line(),
            panel.grid.major = element_line(colour="#f0f0f0"),
            panel.grid.minor = element_blank(),
            legend.key = element_rect(colour = NA),
            legend.position = "top",
            # legend.direction = "verticale",
            # legend.key.size= unit(0.5, "cm"),
           # legend.margin = unit(0, "cm"),
            legend.title = element_blank(),
            plot.margin=unit(c(10,5,5,5),"mm"),
            strip.background=element_rect(colour="#f0f0f0",fill="#f0f0f0"),
            strip.text = element_text()
    ))
}

```

## Define Sites
Multiple sites can be defined under Sites. Project will be the grouping of sites and name of the export folder. read_NWIS if set to TRUE will pull from NWIS web (this can take 10-15 minutes to important instantaneous data), or if set to FALSE will read in local data that is already retrieved and saved from NWIS. After the first NWIS import, data will be saved locally automatically. 

```{r Retrieve gage site information from NWIS}
Sites <- c("01589000","01589025","01589035")
Project <- "Patapsco"
read_NWIS <- TRUE
SiteInfo<-readNWISsite(Sites)
SiteInfo
```

## Plot locations in leaflet
```{r}
leaflet(data = SiteInfo) %>% addTiles() %>%
  addCircleMarkers(~dec_long_va, ~dec_lat_va, color="black", radius=8, popup = ~as.character(paste0(site_no, ": ", station_nm)), label = ~as.character(paste0(site_no, ": ", station_nm)))
```

#Import Gage Data
Let's figure out what data is available at these 3 gage locations
```{r WhatData, eval=FALSE, include=FALSE}
whatNWISdata(siteNumber=Sites, service=c("uv","dv","qw"),statCd = "00003") %>%
  select(agency_cd,site_no,station_nm,parm_cd,stat_cd,begin_date,end_date,count_nu) %>%
  arrange(station_nm, parm_cd, stat_cd) 
```

A few of the main USGS parameter codes used by NWIS:
* 00060 - Discharge
* 00065 - Gage height
* 63680 - Turbidity
* 80154 - SSC
* 80155 - SSQ

We will pull in all data for these parameters for the entire period of record.
```{r dataRetrieval Settings}
startDate <- "2010-10-01"
endDate <- ""
par <- c("00060","00065", "63680", "80154", "80155")
```

If read_NWIS has been previously set to TRUE, this chunk will pull from NWIS web (this can take 10-15 minutes to important instantaneous data) and save a copy locally for later analysis. If read_NWIS has been set to FALSE, this chunk will read in local data that was already retrieved and saved from NWIS. 
```{r Load in data from NWIS or locally based on read_NWIS}
writeDir <<- paste0("./NWIS_pulls/",Project)
if (read_NWIS == TRUE){
  message("Reading uv data")
  uv_data <<- readNWISuv(siteNumbers = Sites,
            parameterCd = par,
            startDate = startDate,
            endDate = "",
            tz = "America/New_York") %>% renameNWISColumns() %>% 
            filter(Flow_Inst!=-999999) %>%
            filter(GH_Inst!=-999999)
  message("Reading dv data")
  par <- c("00060","00065", "63680", "80154", "80155")
  dv_data <<- readNWISdv(siteNumbers = Sites,
            parameterCd = par,
            startDate = startDate,
            endDate = "") %>% renameNWISColumns() 
  SiteInfo<<-readNWISsite(Sites)
  meas <<- readNWISmeas(Sites, 
                     startDate = startDate,
                     endDate = "", 
                     tz = "America/New_York", 
                     expanded = TRUE, 
                     convertType = TRUE)
  message("Writing NWIS data locally for later loads")
  dir_create(writeDir) #Create Export directory
  fwrite(dv_data,paste0(writeDir,"/dv_data.csv"))
  fwrite(uv_data,paste0(writeDir,"/uv_data.csv"))
  fwrite(SiteInfo,paste0(writeDir,"/site_info.csv"))
  fwrite(meas,paste0(writeDir,"/site_meas.csv"))
  } else if(read_NWIS == FALSE)  {
  message("read_NWIS is defined to FALSE. Will read local files")
  message("Reading local Daily Data ")
    dv_data <- fread(paste0(writeDir,"/dv_data.csv"), colClasses=c(site_no="character"))
    dv_data$Date <- as.Date(dv_data$Date)
  message("Reading local Continuous Data")
    uv_data <- fread(paste0(writeDir,"/uv_data.csv"), colClasses=c(site_no="character"))
    uv_data$dateTime <- fastPOSIXct(uv_data$dateTime)
  message("Reading local Site Info")
    site_info <- fread(paste0(writeDir,"/site_info.csv"), colClasses=c(site_no="character"))
  message("Reading local Measurement Data")
    meas_data <- fread(paste0(writeDir,"/site_meas.csv"), colClasses=c(site_no="character"))
  } else{
    message("read_NWIS not defined. Data not loaded")
  }
```

#Analysis of time-series records
Now that we have time-series data loaded into our environment, let's explore what we can see from these datasets.

##Cumulative Daily Value Turbidity and Discharge
Although in practice, this doesn't tell us much about the system, it is still useful to look at the values. In the below plot, we can see that Hollofield has much lower cumulative bars. Why might that be the case?
```{r Generate DV Cumulative Plots, echo=FALSE}
data <-dv_data %>%
  select(Date, site_no,Flow,Turb) %>%
    na.omit() %>% group_by(site_no) %>%  
    filter(Flow!=-999999) %>%
    filter(Turb!=-999999) %>%
    mutate(cumQ=cumsum(Flow),cumT=cumsum(Turb)) %>% ungroup()
plot<-ggplot(data, aes(x=cumQ, y=cumT, group=site_no, color=site_no))+
  geom_path(size=2)+
  theme_ss(14, "sans")+
   ylab("Cumulative Turbidity Trace")+
   xlab("Cumulative Flow in cfs")+
  scale_color_viridis_d(labels=c("Hollofield","Catonsville","Elkridge"))
ggplotly(plot)
```
Now we have plotted both cumulative traces as a function of time. As we can clearly see, the gage at Hollofield was turned off for turbidity at the beginning of the 2016 WY. Elkridge and Catonsville have continued until the present.
```{r Generate time-explicit DV cumulative plots, echo=FALSE}
data %>%
  gather(variable, value, c(cumQ,cumT)) %>%
ggplot(aes(x=Date, y=value, group=site_no, color=site_no))+
  geom_path(size=2) +
  facet_wrap(~variable, scales = "free_y") +
  theme_ss(14, "sans")+
  ylab("Cumulative  Trace")+
  scale_color_viridis_d(labels=c("Hollofield","Catonsville","Elkridge"))
```
##DV SSC Transport Plots
Since we're not actually interested in turbidity, but rather SSC - or better yet SS load - we can plot up the transport plots for each month and see how each site reponds differently to the dam removal. 
```{r Generate DV transport plots By Year and Month}
library(devtools)

p<-dv_data %>%
  group_by(site_no) %>% 
  filter(Flow != -999999) %>%
  filter(Date > "2010-10-28"& Date < "2017-10-1") %>%
  filter(site_no=="01589025"|site_no=="01589035")%>%
  separate(Date, by="-", into = c("Year","Month","Day")) %>%
  unite(MonthYear,Year,Month,sep=".") %>% ungroup()

plot <- ggplot(data=p, aes(x=log(Flow), y=log(`80154`+1), group=site_no, color=site_no, frame=MonthYear))+
  geom_point(size=1.5, alpha=0.5)+
 # theme_ss(14, "sans")+
  ylab("Mean Daily SSC (log units)")+
  xlab("Mean Daily Flow (log units)")+
  scale_color_viridis_d(labels=c("Hollofield","Catonsville","Elkridge"))+
  geom_smooth(method="lm", se=F)
ggplotly(plot)
```

##Analysis of net gain/loss of sediment stage by stage
```{r Net Fain/loss by stage - Table}
cum_dv_data <- dv_data %>%
 # select(Date, site_no,Flow,Turb) %>%
  #na.omit() %>% 
  group_by(site_no) %>%
  filter(Date > "2010-10-1") %>%
  select(site_no, Date,Flow,`80154`, `80155`) %>%
 # separate(Date, by="-", into = c("Year","Month","Day")) %>%
 # unite(MonthYear,Year,Month,sep=".") %>%
  group_by(site_no) %>% mutate(cumQ=cumsum(Flow),cumSSC=cumsum(`80155`)) %>%
  select(site_no,cumSSC,Date) %>%
  spread(site_no,cumSSC) %>%
  mutate(diff00_25 = `01589025`-`01589000`) %>%
  mutate(diff25_35 = `01589035`-`01589025`) 
cum_dv_data
```
```{r Plot the cumulative load data}
cum_dv_data%>%
  gather(key=variable, value=value, -Date) %>%
ggplot(aes(x=Date, y=value, color=variable,group=variable))+
  geom_path(size=2)+
   theme_ss(14, "sans")+
  ylab("Cumulative Sediment Load")+
  scale_color_viridis_d(labels=c("Hollofield","Catonsville","Elkridge","Gain/Loss between\nHollofiend and Catonsville", "Gain/Loss between\nCatonsville and Elkridge"))+
  theme(legend.position="top")+
  geom_hline(yintercept=0, linetype=1)+
  geom_vline(xintercept=as.numeric(as.Date("2010-10-01")), linetype=4)+
  geom_vline(xintercept=as.numeric(as.Date("2018-9-11")), linetype=4)+
  geom_vline(xintercept=as.numeric(as.Date("2018-5-27")), linetype=2)+
  geom_vline(xintercept=as.numeric(as.Date("2016-7-30")), linetype=2)+
  xlim(as.Date("2009-10-01"),as.Date("2018-10-23"))
```
We can look at our dataframe to see how many days are missing values for cumulative load? We expect large numbers at Hollofield since it was turned off at the end of WY2015. The remaining 394 days are for the period of unapproved records in WY2018.
```{r How many days are missing values for cumulative load?}
cum_dv_data %>%
  summarise_all(funs(sum(is.na(.))))
```


## Storm-by-storm analysis
```{r Identify when storms occurred, echo=FALSE}
dv_data %>%
  select(Date, site_no,Flow,Turb) %>%
    na.omit() %>% group_by(site_no) %>% mutate(cumQ=cumsum(Flow),cumT=cumsum(Turb)) %>%
  filter(Date < "2013-1-1") %>%
 # separate(Date, by="-", into = c("Year","Month","Day")) %>%
  #unite(MonthYear,Year,Month,sep=".") %>%
  ggplot(aes(x=Date, y=Flow, group=site_no, color=site_no))+
  geom_line(size=1.5, alpha=0.5)+
  scale_color_viridis_d()+
  ggtitle("Mean Daily Flow at All Patapsco Gages")
```
A smoothing algorithm is applied over the discharge window and used to pick out peaks based on local maxa of the smoothing curve
```{r Storm picker smoothing algorithm, fig.height=10, fig.width=8}
p_load(zoo)
argmax <- function(x, y, w=1, ...) {
  require(zoo)
  n <- length(y)
  y.smooth <- loess(y ~ x, ...)$fitted
  y.max <- rollapply(zoo(y.smooth), 2*w+1, max, align="center")
  delta <- y.max - y.smooth[-c(1:w, n+1-1:w)]
  i.max <- which(delta <= 0) + w
  list(x=x[i.max], i=i.max, y.hat=y.smooth)
}
test <- function(w, span) {
  peaks <- argmax(x, y, w=w, span=span)

  plot(x, y, cex=0.75, col="Gray", main=paste("w = ", w, ", span = ", span, sep=""))
  lines(x, peaks$y.hat,  lwd=2) #$
  y.min <- min(y)
  points(x[peaks$i], peaks$y.hat[peaks$i], col="Red", pch=19, cex=1.25)
}
data <- dv_data %>%
  select(Date, site_no,Flow,Turb) %>%
    na.omit() %>% group_by(site_no) %>% mutate(cumQ=cumsum(Flow),cumT=cumsum(Turb)) %>%
  filter(Date < "2018-1-1") %>% filter(site_no=="01589035")
x <- as.numeric(data$Date)
y <- log(data$Flow)
par(mfrow=c(4,1))
plot(x,y)
lines(x,y)
test(1, 0.003)
test(1, 0.005)
test(2, 0.02)
length(x)
peaks <- argmax(x, y, w=1, span=0.01)
message(length(peaks$x), "storms identified at Site 01589035")
```

```{r Plotting hysteresis of storm, fig.height=4, fig.width=8}
peak.no <- 8
peak_date <- data %>%
  filter(Date %in% as.Date(peaks$x)) %>%
  filter(Turb > 100)
target_peak_long<-format(peak_date[[1]][[peak.no]], format="%B %d, %Y")
target_peak<-peak_date[[1]][[peak.no]]

storm_uv<-uv_data %>%
  #filter(site_no==site) %>%
  filter(dateTime > target_peak-0.2 & dateTime < target_peak+1.2)

temp <- storm_uv %>%
  filter(site_no=="01589035") 
min <- min(temp$dateTime)
mean <- mean(temp$dateTime)
max <- max(temp$dateTime)

storm_uv %>%
  gather(variable, value, c(Flow_Inst,Turb_Inst)) %>%
  #filter(site_no==site) %>%
  ggplot(aes(x=dateTime, y= value, color=as.numeric(dateTime)))+
  geom_path(size=1)+
  facet_grid(variable~site_no, scales = "free_y")+
  scale_color_viridis_c(name="Date and Time",breaks=as.numeric(c(min,mean,max)),labels=c(min, mean, max))+
  ggtitle(paste0("Hydrograph for storm #:",peak.no,"   ", target_peak_long))

data2<-storm_uv %>%
  filter(site_no!="01589000") 
data2$site_no<-factor(data2$site_no)
p<-ggplot(data2,aes(x=Flow_Inst, y=Turb_Inst,color=as.numeric(dateTime)))+
  geom_path(size=2)+
  theme_ss_facet(8)+
  #scale_x_log10()+
  #scale_y_log10()+
  ylab("Instantaneous Turbidity")+
  xlab("Instantaneous Flow (cfs)")+
  guides(fill=FALSE, color=FALSE) +
  theme(axis.title.x = element_text(size=rel(1)), strip.text=element_text(size=rel(0.8)))+
  facet_wrap(~full_name)+
  scale_color_viridis_c(name="Date and Time", breaks=as.numeric(c(min,mean,max)),labels=c(min, mean, max))+
  ggtitle(paste0("Hysteresis loops for storm #:",peak.no,"   ", target_peak))
ggsave(plot = p, filename = "./Presentation_Output/Hysteresis_9.png", height = 3, width = 6)

```

```{r Loop plot to save all hysteresis results, eval=FALSE, include=FALSE}
for (i in seq(peaks$x)){
tryCatch({
 peak.no <- i
peak_date <- data %>%
  filter(Date %in% as.Date(peaks$x)) %>%
  filter(Flow > 200)
target_peak_long<-format(peak_date[[1]][[peak.no]], format="%B %d, %Y")
target_peak<-peak_date[[1]][[peak.no]]
target_peak <- paste0("./Patapsco_Hysteresis/")
dir_create(target_peak) #Create Export directory

storm_uv<-uv_data %>%
  #filter(site_no==site) %>%
  filter(dateTime > target_peak-1 & dateTime < target_peak+3)

temp <- storm_uv %>%
  filter(site_no=="01589035") 
min <- min(temp$dateTime)
mean <- mean(temp$dateTime)
max <- max(temp$dateTime)
storm_uv$dateTime

storm_uv %>%
  gather(variable, value, c(Flow_Inst,Turb_Inst)) %>%
  #filter(site_no==site) %>%
  ggplot(aes(x=dateTime, y= value, color=as.numeric(dateTime)))+
  geom_path(size=1)+
  facet_grid(variable~site_no, scales = "free_y")+
  theme_bw()+
  scale_color_viridis_c(name="Date and Time",breaks=as.numeric(c(min,mean,max)),labels=c(min, mean, max))+
  ggtitle(paste0("Hydrograph for storm #:",peak.no,"   ", target_peak_long))
# ggsave(paste0(,"Storm-",i," Hydrograph.png"),width=9,height=6)

storm_uv %>%
  ggplot(aes(x=Flow_Inst, y=Turb_Inst,color=as.numeric(dateTime)))+
  geom_path(size=2)+
  theme_bw()+
  facet_wrap(~site_no)+
  scale_color_viridis_c(name="Date and Time", breaks=as.numeric(c(min,mean,max)),labels=c(min, mean, max))+
  ggtitle(paste0("Hysteresis loops for storm #:",peak.no,"   ", target_peak))
#ggsave(paste0(,"Storm-",i," Hysteresis.png"),width=12)
})
}

```

```{r Loop plot for all hysteresis results for 1 site, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
site <- "01589025"

seq <- 173:185
groblength<-1
plot_list = list()
for (i in seq){
peak.no <- i

peak_date <- data %>%
  filter(Date %in% as.Date(peaks$x)) %>%
  filter(Flow > 200)

target_peak<-peak_date[[1]][[peak.no]]
  
storm_uv<-uv_data %>%
  filter(site_no==site) %>%
  filter(dateTime > target_peak-2 & dateTime < target_peak+2)

temp <- storm_uv %>%
  filter(site_no=="01589035") 
min <- min(temp$dateTime)
mean <- mean(temp$dateTime)
max <- max(temp$dateTime)


name <-paste0("plot",i) 
plot_list[[groblength]] <- ggplot(storm_uv,aes(x=Flow_Inst, y=Turb_Inst,color=as.numeric(dateTime)))+
                      geom_path(size=2)+
                      theme_bw(base_size = 8)+
                      scale_color_viridis_c(name="Date and Time", breaks=as.numeric(c(min,mean,max)),labels=c(min, mean, max))+
                      ggtitle(paste0("#",peak.no," - ", target_peak))+ guides(color=FALSE)
groblength <- groblength+1
}

g<-do.call(arrangeGrob,plot_list)

#ggsave(file=paste0(,"Hysteresis",site,"-", min(seq),"-", max(seq),".png"), g, height=7, width=7) #saves g

```
```{r tidy attempted remake of above, eval=FALSE, include=FALSE}
site <- "01589035"

list_data = list()

for (i in seq(peaks$x)){
peak.no <- i
peak_date <- data %>%
  filter(Date %in% as.Date(peaks$x))

target_peak<-peak_date[[1]][[peak.no]]
  
storm_uv<-uv_data %>%
  filter(dateTime > target_peak-2 & dateTime < target_peak+2)
start<-storm_uv$dateTime[[1]]
storm_uv<-storm_uv %>% 
  mutate(timefrom = (dateTime-start))
storm_uv$i <- i
storm_uv$storm_id <- paste0("Storm #",peak.no," - ", target_peak)
list_data[[i]] <- storm_uv
}

storm_data<-rbindlist(list_data)

storm_data %>%
  #filter(site_no==site) %>%
  filter(i>=170 & i <= 186) %>%
  ggplot(aes(x=Flow_Inst, y=Turb_Inst))+
    geom_path(size=2, alpha=0.8, aes(color=factor(site_no)))+
    scale_x_log10()+
  scale_y_log10()+
              theme_bw(base_size = 8)+
                #      scale_color_viridis_d(name="Date and Time", breaks=as.numeric(c(min,mean,max)),labels=c(min, mean, max))+
                      ggtitle(paste0("Hysteresis Grid for USGS Site  ",site))+
  #guides(color=FALSE)+
  facet_wrap(~storm_id)
  
```

#Discrete Sediment Data Analysis
This data pull for the discrete data is not working and I'm not sure why. Still needs to be diagnosed and fixed.
```{r Hysteresis loop information based on discrete data available}
# pCode <- c("69309","69314","70331","70332","70333","70334","70335","70336","80154","80155")
# discrete <- readNWISdata(siteNumbers = Sites, parameterCd = pCode,
#                       startDate = startDate, endDate = endDate,
#                       service = "qw")

```

